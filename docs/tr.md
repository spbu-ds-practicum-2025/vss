# Техническое решение проекта «Map-Reduce word count»

## Введение

**Цель проекта:**
Разработать распределенную систему на основе парадигмы Map-Reduce для задачи подсчета количества слов в документе (word count). Проект служит демонстрацией принципов распределенных вычислений и отказоустойчивой обработки данных.

**Основания для разработки:**
Учебный проект в рамках курса «Основы распределенных вычислений». Проект демонстрирует практическое применение MapReduce-подхода для обработки текстовых документов.

**Команда:**
- Александр Кука – Архитектор
- Клименко Степан – Аналитик / Тестировщик  
- Cкудаева Варвара – Data Engineer
- Полежаев Владислав - Разработчик


## Глоссарий

| Термин | Определение |
|---|---|
| **MapReduce** | Модель распределённых вычислений для параллельной обработки больших данных путем разделения задачи на этапы |
| **Map (Фаза отображения)** | Стадия обработки, на которой входные данные разбиваются на части и обрабатываются параллельно для генерации промежуточных пар ключ-значение |
| **Reduce (Фаза свертки)** | Стадия обработки, на которой промежуточные данные группируются по ключу и агрегируются для формирования финального результата |
| **Planner (Планировщик)** | Компонент, отвечающий за нарезку задач на части и распределение частей по узлам |
| **Task Manager** | Центральный сервис, управляющий жизненным циклом задачи: получение задачи, контроль выполнения, выдача результатов |
| **Универсальный Узел (Worker Node)** | Вычислительный узел в кластере, способный выполнять как Map так и Reduce задачи |
| **Shuffle & Sort** | Этап между Map и Reduce, на котором промежуточные пары ключ-значение группируются по ключу и сортируются перед отправкой на Reduce-узлы |
| **Чанк (Chunk)** | Часть входного документа, обрабатываемая на этапе Map |
| **Воркер (Worker)** | Процесс, выполняющий задачи Map или Reduce на узле |

## Функциональные требования

Система должна предоставлять следующие функции:

1. **Загрузка документа** – Пользователь загружает текстовый документ через Task Manager
2. **Распределение задач** – Planner разбивает документ на чанки и распределяет Map-задачи между доступными узлами
3. **Параллельный подсчет слов** – Узлы выполняют Map-задачи, обрабатывая свои чанки и генерируя промежуточные данные (`<слово, 1>`)
4. **Сохранение промежуточных результатов** – Результаты Map-этапа сохраняются в БД для обеспечения отказоустойчивости
5. **Агрегация результатов** – Система автоматически выполняет этап Shuffle & Sort, группируя промежуточные данные по словам
6. **Формирование выходного файла** – Узлы, назначенные на Reduce-задачи, суммируют количества для каждого слова
7. **Сохранение финальных результатов** – Финальный результат сохраняется в базу данных
8. **Уведомление о завершении** – Task Manager отслеживает результат и уведомляет пользователя о завершении задачи

## Нефункциональные требования

**Производительность**
- Обработка документа объемом 1 ГБ должна быть завершена не более чем за 10 минут
- Система должна демонстрировать линейное или близкое к линейному ускорение при добавлении новых узлов

**Масштабируемость**
- Архитектура позволяет горизонтально масштабироваться за счет добавления новых Универсальных Узлов

**Надежность и отказоустойчивость**
- Task Manager должен отслеживать "здоровье" узлов
- В случае падения узла задача должна быть переназначена другому доступному узлу с механизмом дедупликации
- Промежуточные результаты этапа Map сохраняются в устойчивое хранилище для избежания потерь
- Обнаружение и повторная обработка потерянных чанков

**Простота использования**
- Процесс загрузки документа и получения результата должен быть интуитивно понятен

## Модель взаимодействия

**Асинхронная коммуникация**
- Все взаимодействия между компонентами реализуются через асинхронные сообщения
- Task Manager и Planner взаимодействуют через очередь задач
- Worker узлы получают задачи через брокер сообщений
- Через брокер передаются ссылки на входные и выходные данные, которые хранятся в DB_PW
- Промежуточные результаты сохраняются в БД асинхронно

**Преимущества асинхронного подхода:**
- Отказоустойчивость - сообщения не теряются при временной недоступности компонентов
- Масштабируемость - можно добавлять обработчиков без изменения архитектуры
- Развязка компонентов - каждый сервис работает независимо

## Пользовательские сценарии

**Сценарий: Постановка задачи на обработку**
1. Пользователь загружает документ через Task Manager
2. Система подтверждает прием задачи и присваивает идентификатор
3. Пользователь получает идентификатор для отслеживания статуса

**Сценарий: Получение результата обработки**
1. Пользователь запрашивает статус задачи по идентификатору
2. Система возвращает текущий статус выполнения
3. При завершении обработки пользователь получает файл с результатами подсчета слов

## Архитектура системы

```mermaid
---
config:
  theme: redux
  flowchart: {}
  layout: elk
---
flowchart TD
 subgraph Workers["Workers"]
        n2["Worker 1"]
        n3["Worker 2"]
        n4["Worker 3"]
  end
 subgraph app[" "]
        Workers
        n5["Task_Manager"]
        n6["DB_TM"]
        n9["Shuffle_Manager"]
        n1["Message_queue"]
        C["Planner"]
        B["Gateaway_API"]
        n7["S3_PW"]
  end
    A(["Client"]) <--> B
    B <--> C
    C --> n9 & n1
    n9 --> n7
    Workers --> n1 & n7
    n5 --> n1 & n6
    n6@{ shape: disk}
    n1@{ shape: rect}
    B@{ shape: rect}
    n7@{ shape: disk}
     n2:::Sky
     n3:::Sky
     n4:::Sky
     n5:::Peach
     n6:::Class_02
     n9:::Peach
     n1:::Class_01
     C:::Rose
     B:::Aqua
     n7:::Class_02
     A:::Ash
    classDef Sky stroke-width:1px, stroke-dasharray:none, stroke:#374D7C, fill:#E2EBFF, color:#374D7C
    classDef Pine stroke-width:1px, stroke-dasharray:none, stroke:#254336, fill:#27654A, color:#FFFFFF
    classDef Peach stroke-width:1px, stroke-dasharray:none, stroke:#FBB35A, fill:#FFEFDB, color:#8F632D
    classDef Rose stroke-width:1px, stroke-dasharray:none, stroke:#FF5978, fill:#FFDFE5, color:#8E2236
    classDef Aqua stroke-width:1px, stroke-dasharray:none, stroke:#46EDC8, fill:#DEFFF8, color:#378E7A
    classDef Ash stroke-width:1px, stroke-dasharray:none, stroke:#999999, fill:#EEEEEE, color:#000000
    classDef Class_01 fill:#E1BEE7
    classDef Class_02 stroke-width:2px, stroke-dasharray: 0, stroke:#FFFFFF, fill:#C8E6C9
```

Система построена по гибридной архитектуре "Master-Worker" в рамках парадигмы MapReduce.

### Компоненты системы

**Task Manager**
- Центральный сервис управления задачами
- Управляет жизненным циклом задачи
- Отслеживает статус выполнения через базу данных
- Уведомляет Planner о сбоях для повторной отправки нужного чанка на обработку


**Planner**
- Принимает задачи от пользователя и выдает результаты
- Разбивает документы на чанки (параметризуемое количество)
- Распределяет Map и Reduce задачи между Worker узлами через брокер сообщений
- Обрабатывает сбои узлов с механизмом дедупликации
- Уведомляет пользователя о завершении

**Data Manager**
- Принимает от Planner'а документ пользователя и делит его на заданное количество чанков
- Сохраняет чанки в хранилище и уведомляет Planner об окончании сохранения последнего чанка
- По заданной логике проводит для промежуточных данных, добавленных после Map-фазы, этап Shuffle
- По запросу Planner'а очищает хранилище перед обарботкой нового запроса пользователя

**Workers**
- Исполняющие узлы, способные выполнять обе функции:
- **Map**: Принимает фрагмент текста, разбивает на отдельные слова, формирует промежуточные результаты в формате "(<слово>, 1)" и сохраняет в БД
- **Reduce**: Получает сгруппированные данные по определённым словам, складывает все единицы и вычисляет итоговое количество для каждого слова
- Также каждый узел с заданным интервалом отправлет Task manager'у сообщение о том, что работает, в случае отсутствия таких сообщений Task Manager будет считать узел вышедшим из строя

**Message Queue (Брокер сообщений)**
- Обеспечивает асинхронную коммуникацию между компонентами
- Гарантирует доставку сообщений даже при временной недоступности компонентов
- Поддерживает персистентное хранение задач
- Обеспечивает механизм подтверждения обработки

**S3_PW**
- Хранилище для начальных чанков, промежуточных и финальных результатов
- Отслеживание статуса задач и узлов
- Обеспечивает сохранность данных при сбоях

**DB_TM**
- Хранит метаданные, необходимые для Task Manager (какой чанк обрабатываеися на каком узле, как операция над ним выполняется, статус узлов и тому подобное)

## Технические сценарии

### Сценарий 1: Успешное выполнение задачи

1. **Инициализация задачи:**

   - Пользователь загружает документ через Planner, указывая количество чанков n
   - Planner отправляет документ в Data Manger
   - Data Manger делит документ на чанки, сохраняет их в S3_PW и посылает в брокер сообщению информацию о завершении записи
   - Planner получвет сообщение о том, что все чанки созранены в хранилище

2. **Планирование и распределение Map-задач:**
   - Planner публикует n Map-задач в брокер сообщений

3. **Выполнение Map-фазы:**
   - n доступных Worker узлов получают Map-задачи из брокера сообщений
   - Каждый Worker выполняет Map-обработку своего чанка, генерируя промежуточные данные
   - Worker сохраняет промежуточные результаты в БД
   - Worker отправляет подтверждение выполнения в брокер сообщений

4. **Этап Shuffle**
   - Task Manager отслеживает завершение всех Map-задач через сообщения в брокере
   - После получения всех подтверждений Task Manager уведомляет об этом Planner
   - Planner обращается к Data Manager, чтобы тот по заданным правилам перемешал промежуточные данные и разбил их на новые чанки
   - Planner получает от Data Manager сообщения о завершении shuffle, после чего Planner публикует n Reduce-задач в брокер сообщений

5. **Выполнение Reduce-фазы:**
   - Worker узлы получают Reduce-задачи из брокера сообщений
   - Workers читают сгруппированные промежуточные данные из БД
   - Workers выполняют Reduce-обработку, суммируя значения для каждого слова
   - Workers сохраняют финальные результаты в БД
   - Workers отправляют подтверждения выполнения в брокер сообщений

6. **Завершение задачи:**
   - Task Manager периодически проверяет статус задачи в БД
   - При обнаружении финальных результатов Task Manager уведомляет Planner о завершении
   - Planner уведомляет пользователя о готовности результата
   - Planner делает запрос столбца с результатами из S3_PW и отправляет его пользователю

   
### Сценарий 2: Обработка сбоя узла во время Map-фазы

1. Worker Node перестает отвечать во время выполнения Map-задачи
2. Task Manager обнаруживает сбой через механизм health-check (таймауты)
3. Planner проверяет в БД - промежуточные результаты не сохранены
4. Planner повторно ставит Map-задачу в очередь
5. Другой Worker обрабатывает чанк и сохраняет результаты в БД
6. Процесс продолжается с этапа Shuffle 

### Сценарий 3: Обработка сбоя узла после Map-фазы

1. Worker Node завершил Map-обработку и сохранил результаты в БД
2. Узел перестает отвечать перед Reduce-фазой
3. Task Manager обнаруживает сбой, но видит в БД сохраненные промежуточные результаты
4. Planner назначает Reduce-задачу другому узлу, используя сохраненные данные
5. Потеря данных не происходит

## План разработки
### MVP
1. **Реализация Task Manager** (прием задач от пользователя, управление жизненным циклом задачи, выдача результатов)
2. **Реализация Planner** (разбиение документов на чанки, распределение Map и Reduce задач)
3. **Реализация Worker узлов** (выполнение Map операций - разбиение текста на слова)
4. **Реализация базового Shuffle & Sort** (группировка промежуточных данных по словам)
5. **Интеграция с базой данных** (хранение документов, промежуточных и финальных результатов)
6. **Реализация брокера сообщений** (асинхронная коммуникация между компонентами)
7. **Базовая отказоустойчивость** (повторная обработка задач при сбоях Worker узлов)
8. **Интеграционное тестирование** (проверка работы всей цепочки обработки от загрузки до выдачи результата)


### Детальный план реализации

**Фаза 1: Прототип на одном узле**
- Цель: Реализовать логику Map и Reduce в рамках одного приложения
- Результат: Консольное приложение для word count

**Фаза 2: База данных и асинхронная коммуникация**
- Цель: Реализовать устойчивое хранение и брокер сообщений
- Результат: Интеграция с БД и Message Queue

**Фаза 3: Planner и один Worker (MVP)**
- Цель: Разделить ответственность между компонентами
- Результат: Два приложения, коммуницирующих через MQ

**Фаза 4: Распределение Map-задач**
- Цель: Реализовать запуск нескольких Worker'ов
- Результат: Planner может отправить чанки разным Worker'ам

**Фаза 5: Shuffle & Sort и Reduce-задачи**
- Цель: Организовать передачу данных между Worker'ами
- Результат: Полностью работоспособный конвейер MapReduce

**Фаза 6: Task Manager и отказоустойчивость**
- Цель: Добавить централизованное управление и механизмы восстановления
- Результат: Полная отказоустойчивость системы

**Фаза 7: Пользовательский веб-интерфейс**
- Цель: Предоставить удобный способ взаимодействия
- Результат: Веб-интерфейс для загрузки документов и получения результатов

## Тестирование

**Интеграционное тестирование (Integration Testing)**
- Тестирование взаимодействия между **Planner** и **Worker**
- Тестирование взаимодействия **Worker** с БД
- Тестирование цикла **Task Manager** → **БД** → **Planner**

**Системное тестирование (System / End-to-End Testing)**
- Запуск всего кластера с тестовыми документами разного размера
- Проверка корректности и полноты итогового результата
- Проверка работы под нагрузкой

**Тестирование отказоустойчивости (Failure Testing)**
- Имитация падения Worker'а во время выполнения задач
- Проверка переназначения задач и корректности конечного результата
- Проверка восстановления системы после перезапуска узлов

### DOD
- Система должна корректно решать задачу подсчета слов (word count)
- Система должна решать задачу распределено в соответствии с заявленной архитектурой



