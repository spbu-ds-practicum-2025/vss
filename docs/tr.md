# Техническое решение проекта «Map-Reduce word count»

## Введение

**Цель проекта:**
Разработать распределенную систему на основе парадигмы Map-Reduce для задачи подсчета количества слов в документе (word count). Проект служит демонстрацией принципов распределенных вычислений и отказоустойчивой обработки данных.

**Основания для разработки:**
Учебный проект в рамках курса «Основы распределенных вычислений». Проект демонстрирует практическое применение MapReduce-подхода для обработки текстовых документов.

**Команда:**
- Александр Кука – Архитектор
- Клименко Степан – Аналитик / Тестировщик  
- Cкудаева Варвара – Data Engineer
- Полежаев Владислав - Разработчик


## Глоссарий

| Термин | Определение |
|---|---|
| **MapReduce** | Модель распределённых вычислений для параллельной обработки больших данных путем разделения задачи на этапы |
| **Map (Фаза отображения)** | Стадия обработки, на которой входные данные разбиваются на части и обрабатываются параллельно для генерации промежуточных пар ключ-значение |
| **Reduce (Фаза свертки)** | Стадия обработки, на которой промежуточные данные группируются по ключу и агрегируются для формирования финального результата |
| **Planner (Планировщик)** | Компонент, отвечающий за нарезку задач на части и распределение частей по узлам |
| **Task Manager** | Центральный сервис, управляющий жизненным циклом задачи: получение задачи, контроль выполнения, выдача результатов |
| **Универсальный Узел (Worker Node)** | Вычислительный узел в кластере, способный выполнять как Map так и Reduce задачи |
| **Shuffle & Sort** | Этап между Map и Reduce, на котором промежуточные пары ключ-значение группируются по ключу и сортируются перед отправкой на Reduce-узлы |
| **Чанк (Chunk)** | Часть входного документа, обрабатываемая на этапе Map |
| **Воркер (Worker)** | Процесс, выполняющий задачи Map или Reduce на узле |

## Функциональные требования

Система должна предоставлять следующие функции:

1. **Загрузка документа** – Пользователь загружает текстовый документ через Task Manager
2. **Распределение задач** – Planner разбивает документ на чанки и распределяет Map-задачи между доступными узлами
3. **Параллельный подсчет слов** – Узлы выполняют Map-задачи, обрабатывая свои чанки и генерируя промежуточные данные (`<слово, 1>`)
4. **Сохранение промежуточных результатов** – Результаты Map-этапа сохраняются в S3_PW для обеспечения отказоустойчивости
5. **Агрегация результатов** – Система автоматически выполняет этап Shuffle & Sort, группируя промежуточные данные по словам
6. **Формирование выходного файла** – Узлы, назначенные на Reduce-задачи, суммируют количества для каждого слова
7. **Сохранение финальных результатов** – Финальный результат сохраняется в базу данных
8. **Уведомление о завершении** – Task Manager отслеживает результат и уведомляет пользователя о завершении задачи

## Нефункциональные требования

**Производительность**
- Обработка документа объемом 1 ГБ должна быть завершена не более чем за 10 минут
- Система должна демонстрировать линейное или близкое к линейному ускорение при добавлении новых узлов

**Масштабируемость**
- Архитектура позволяет горизонтально масштабироваться за счет добавления новых Универсальных Узлов

**Надежность и отказоустойчивость**
- Task Manager должен отслеживать "здоровье" узлов
- В случае падения узла задача должна быть переназначена другому доступному узлу с механизмом дедупликации
- Промежуточные результаты этапа Map сохраняются в устойчивое хранилище для избежания потерь
- Обнаружение и повторная обработка потерянных чанков

**Простота использования**
- Процесс загрузки документа и получения результата должен быть интуитивно понятен

## Модель взаимодействия

**Асинхронная коммуникация**
- Все взаимодействия между компонентами реализуются через асинхронные сообщения
- Task Manager и Planner взаимодействуют через очередь задач
- Worker узлы получают задачи через брокер сообщений
- Через брокер передаются ссылки на входные и выходные данные, которые хранятся в S3_PW
- Промежуточные результаты сохраняются в БД асинхронно

**Преимущества асинхронного подхода:**
- Отказоустойчивость - сообщения не теряются при временной недоступности компонентов
- Масштабируемость - можно добавлять обработчиков без изменения архитектуры
- Развязка компонентов - каждый сервис работает независимо

## Пользовательские сценарии

**Сценарий: Постановка задачи на обработку**
1. Пользователь загружает документ через Task Manager
2. Система подтверждает прием задачи и присваивает идентификатор
3. Пользователь получает идентификатор для отслеживания статуса

**Сценарий: Получение результата обработки**
1. Пользователь запрашивает статус задачи по идентификатору
2. Система возвращает текущий статус выполнения
3. При завершении обработки пользователь получает файл с результатами подсчета слов

## Архитектура системы

```mermaid
---
config:
  theme: redux
  flowchart: {}
  layout: elk
---
flowchart TD
 subgraph Workers["Workers"]
        n2["Worker 1"]
        n3["Worker 2"]
        n4["Worker 3"]
  end
 subgraph app[" "]
        Workers
        n5["Task_Manager"]
        n6["DB_TM"]
        n9["Data_Manager"]
        n1["Message_queue"]
        C["Planner"]
        B["Gateaway_API"]
        n7["S3_PW"]
  end
    A(["Client"]) <--> B
    B --> n7
    B <--> C
    C --> n9 & n1
    n9 --> n7
    Workers --> n1 & n7
    n5 --> n1 & n6
    n6@{ shape: disk}
    n1@{ shape: rect}
    B@{ shape: rect}
    n7@{ shape: disk}
```

Система построена по гибридной архитектуре "Master-Worker" в рамках парадигмы MapReduce.

### Компоненты системы

**Task Manager**
- Отслеживает состояние воркеров и сохраняет метаданные об их состоянии в базу данных(DB_TM)
- Уведомляет Planner о сбоях для повторной отправки нужного чанка на обработку
- Уведомляет Planner об окончании Map-Shuffle/Reduce фаз


**Planner**
- Принимает задачи от API Gateaway 
- Распределяет Map и Reduce задачи между Worker узлами через брокер сообщений
- Обрабатывает сбои узлов с механизмом дедупликации
- Отдает Data Manager команлу о формировании результирующего файла


**API Gateaway**
- Получает от пользователя задачу через HTTP-запрос
- Получает от пользователя запрос на проверку статуса задачи
- Если задача выполнена, то на запрос проверки возвращается ссылка на результат в S3 хранилище


**Data Manager**
- Принимает от Planner'а документ пользователя и делит его на заданное количество чанков
- Сохраняет чанки в хранилище и уведомляет Planner об окончании сохранения последнего чанка
- По запросу Planner'а формирует результирующий файл и очищает хранилище от промежуточных данных

**Workers**
- Исполняющие узлы, способные выполнять обе функции:
- **Map-Shuffle**: Принимает фрагмент текста, разбивает на отдельные слова, формирует промежуточные результаты в формате "(<слово>, n)" и сохраняет в S3_PW
- **Reduce**: Получает сгруппированные данные по определённым словам, складывает все значения и вычисляет итоговое количество для каждого слова
- Также каждый узел с заданным интервалом отправлет Task manager'у сообщение о том, что работает, в случае отсутствия таких сообщений Task Manager будет считать узел вышедшим из строя

**Message Queue (Брокер сообщений)**
- Обеспечивает асинхронную коммуникацию между компонентами
- Гарантирует доставку сообщений даже при временной недоступности компонентов
- Поддерживает персистентное хранение задач
- Обеспечивает механизм подтверждения обработки

**S3_PW**
- Хранилище для начальных чанков, промежуточных и финальных результатов
- Обеспечивает сохранность данных при сбоях

**DB_TM**
- Хранит метаданные, необходимые для Task Manager (какой чанк обрабатываеися на каком узле, как операция над ним выполняется, статус узлов и тому подобное)


## Технические сценарии

### Сценарий 1: Успешное выполнение задачи

1. **Инициализация задачи:**

   - Пользователь загружает документ через API Gateaway
   - API Gateaway загружает файл в S3 хранилище и уведомляет об этом Planner
   - Planner отдает команжу Data Manager, чтобы тот разбил файл на чанки и сохранил их в S3_PW
   - Data Manger делит документ на n чанков, сохраняет их в S3_PW и посылает в брокер сообщению информацию о завершении записи
   - Planner получает сообщение о том, что все чанки созранены в хранилище

2. **Планирование и распределение Map-задач:**
   - Planner публикует n Map-задач в брокер сообщений

3. **Выполнение Map-фазы:**
   - Доступные Worker узлы получают Map-задачи из брокера сообщений
   - Каждый Worker выполняет Map-обработку своего чанка, проводит этап Shuffle для своих промежуточных данных
   - Worker сохраняет результаты в S3_PW
   - Worker отправляет подтверждение выполнения в брокер сообщений

   - Task Manager уведомляет Planner о завершении Map-Shuffle фазы

4. **Планирование и распределение Map-задач:**
   - Planner публикует k Reduce-задач в брокер сообщений

5. **Выполнение Reduce-фазы:**
   - Worker узлы получают Reduce-задачи из брокера сообщений
   - Workers читают сгруппированные промежуточные данные из S3_PW
   - Workers выполняют Reduce-обработку, суммируя значения для каждого слова
   - Workers сохраняют финальные результаты в S3_PW
   - Workers отправляют подтверждения выполнения в брокер сообщений

   - Task Manager уведомляет Planner о завершении Reduce фазы

6. **Завершение задачи:**
   -  Planner отдает команду Data Manager, чтобы тот скомпоновал итоговый файл, записал его в S3_PW и очистил S3_PW от промежуточных данных
   - По запросу из S3 хранилища пользователь получает ссылку на результат обработки

```mermaid
---
config:
  theme: redux
  flowchart: {}
  layout: fixed
---
sequenceDiagram
  participant n1 as Client
  participant n2 as API Gateaway
  participant n3 as S3_PW
  participant n4 as Planner
  participant n5 as Data Manager
  participant n6 as S3_PW
  participant n7 as Message Queue
  participant n8 as Workers
  participant n9 as Task Manager
  participant n10 as DB_TM
  n1 ->> n2: POST/add_file(txt или json)
  n2 ->> n3: Запись полученного файла
  n3 ->> n4: Уведомление (через брокер) PLanner'а о появлении нового файла
  n4 ->> n5: Говорит Data Manager разделить файл на заданное количество чанков
  n5 ->> n6: Запись чанков в S3_PW
  n6 -->> n5: 
  n5 -->> n4: Сообщает о завершении разбиения
  n4 ->> n7: Передача в брокер Map-задач
  n7 ->> n8: Workers разбирают Map-задачи
  n8 ->> n9: Отправляют TM сообщения о выполняемых задачах
  n9 ->> n10: Записывает метаданные воркеров в DB_TM
  n10 -->> n9:
  n8 ->> n6: Записывают промежуточные данные в S3_PW
  n6 -->> n8: 
  n8 ->> n9: Уведомляют TM о завершении выполнения Map-задач
  n9 -->> n4: Сообщает Planner'у о завершении Map-Shuffle фазы
  n4 ->> n7: Передача в брокер Reduce-задач
  n7 ->> n8: Workers разбирают Reduce-задачи
  n8 ->> n9: Отправляют TM сообщения о выполняемых задачах
  n9 ->> n10: Записывает метаданные воркеров в DB_TM
  n10 -->> n9:
  n8 ->> n6: Записывают итоговые данные в S3
  n6 -->> n8: 
  n8 ->> n9: Уведомляют TM о завершении выполнения Reduce-задач
  n9 -->> n4: Сообщает Planner'у о завершении Reduce фазы
  n4 ->> n5: Говорит Data Manager скомпоновать итоговый файл и очистить хранилище от промежуточных данных
  n5 -->> n1: По запросу пользователя ему отправляется ссылка на S3 хранилище с результатами
```

   
### Сценарий 2: Обработка сбоя узла во время Map-фазы

1. Worker Node перестает отправлять сигналы во время выполнения Map-задачи
2. Task Manager обнаруживает сбой через механизм health-check (таймауты)
3. Planner проверяет в S3_PW - промежуточные результаты не сохранены
4. Planner повторно ставит Map-задачу в очередь
5. Другой Worker обрабатывает чанк и сохраняет результаты в S3_PW
6. Процесс продолжается с этапа Shuffle 

### Сценарий 3: Обработка сбоя узла после Map-фазы

1. Worker Node завершил Map-обработку и сохранил результаты в S3_PW
2. Узел перестает отвечать перед Reduce-фазой
3. Task Manager обнаруживает сбой, но видит в S3_PW сохраненные промежуточные результаты
4. Planner назначает Reduce-задачу другому узлу, используя сохраненные данные
5. Потеря данных не происходит

## План разработки
### MVP
1. **Реализация Task Manager** (прием задач от пользователя, управление жизненным циклом задачи, выдача результатов)
2. **Реализация Planner** (разбиение документов на чанки, распределение Map и Reduce задач)
3. **Реализация Worker узлов** (выполнение Map операций - разбиение текста на слова)
4. **Реализация базового Shuffle & Sort** (группировка промежуточных данных по словам)
5. **Интеграция с базой данных** (хранение документов, промежуточных и финальных результатов)
6. **Интеграция брокера сообщений RabbitMQ** (асинхронная коммуникация между компонентами)
7. **Базовая отказоустойчивость** (повторная обработка задач при сбоях Worker узлов)
8. **Интеграционное тестирование** (проверка работы всей цепочки обработки от загрузки до выдачи результата)


### Детальный план реализации

**Фаза 1: Прототип на одном узле**
- Цель: Реализовать логику Map и Reduce в рамках одного приложения
- Результат: Консольное приложение для word count

**Фаза 2: База данных и асинхронная коммуникация**
- Цель: Реализовать устойчивое хранение и брокер сообщений
- Результат: Интеграция с БД и Message Queue

**Фаза 3: Planner и один Worker (MVP)**
- Цель: Разделить ответственность между компонентами
- Результат: Два приложения, коммуницирующих через MQ

**Фаза 4: Распределение Map-задач**
- Цель: Реализовать запуск нескольких Worker'ов
- Результат: Planner может отправить чанки разным Worker'ам

**Фаза 5: Shuffle & Sort и Reduce-задачи**
- Цель: Организовать передачу данных между Worker'ами
- Результат: Полностью работоспособный конвейер MapReduce

**Фаза 6: Task Manager и отказоустойчивость**
- Цель: Добавить централизованное управление и механизмы восстановления
- Результат: Полная отказоустойчивость системы

**Фаза 7: Пользовательский веб-интерфейс**
- Цель: Предоставить удобный способ взаимодействия
- Результат: Веб-интерфейс для загрузки документов и получения результатов

## Тестирование

**Интеграционное тестирование (Integration Testing)**
- Тестирование взаимодействия между **Planner** и **Worker**
- Тестирование взаимодействия **Worker** с S3_PW
- Тестирование цикла **Task Manager** → **DB_TM** → **Planner**

**Системное тестирование (System / End-to-End Testing)**
- Запуск всего кластера с тестовыми документами разного размера
- Проверка корректности и полноты итогового результата
- Проверка работы под нагрузкой

**Тестирование отказоустойчивости (Failure Testing)**
- Имитация падения Worker'а во время выполнения задач
- Проверка переназначения задач и корректности конечного результата
- Проверка восстановления системы после перезапуска узлов

### DOD
- Система должна корректно решать задачу подсчета слов (word count)
- Система должна решать задачу распределено в соответствии с заявленной архитектурой



